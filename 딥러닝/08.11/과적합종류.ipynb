{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과적합은 학습횟수에서도,네트워크 횟수에 의해서도 달라질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.기존 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# header=None을 써버려서 60번째 행에 R이 들어가서 그럼. 원래 column에 이름이 없었던 것 같음. 그래서 'R'로 대체\n",
    "df = pd.read_csv('./datasets/sonar.csv',header=None)\n",
    "df.head(10)\n",
    "\n",
    "# feature와 label분리\n",
    "# 요기서 에러가 난 거 같은데 왜 났는진 모를;\n",
    "dataset = df.values\n",
    "\n",
    "# X는 0부터 59번째 열까지 가지고 오고, y는 60번째 행만 가지고 옴\n",
    "X = df.loc[:, 0:59]\n",
    "# 60번째에 R이 없음\n",
    "# x = np.asarray().astype(np.float32)\n",
    "y = df.loc[:,60]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5385\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.5865\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.7019\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.7212\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6971\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7404\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7837\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7788\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8029\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8125\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8077\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8221\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7933\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7837\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8173\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8221\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.7885\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8221\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8221\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8317\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8413\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8365\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8462\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8510\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8510\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8510\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8798\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8462\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8846\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8702\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8654\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8846\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8798\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.8798\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.8798\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2912 - accuracy: 0.8750\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.8942\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2843 - accuracy: 0.8990\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2713 - accuracy: 0.8990\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.8942\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.8846\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.9135\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9135\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.8894\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9087\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9279\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9038\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9087\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9038\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9231\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9231\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9231\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9231\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9375\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.9423\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.9231\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.9279\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9519\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.9471\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9279\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.9423\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9327\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9663\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9423\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9471\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9615\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9663\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9615\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9471\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9712\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9567\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9663\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9808\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9760\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9712\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9904\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9808\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.9856\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9760\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9808\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.9856\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9856\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9808\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9615\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9663\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9808\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9808\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.9567\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9904\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9856\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9760\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9904\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9856\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9904\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9856\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9952\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9904\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9904\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9904\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9904\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9952\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9904\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9952\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9952\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9952\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9952\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9952\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9952\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9952\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9904\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0376 - accuracy: 0.9952\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0331 - accuracy: 0.9952\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9952\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 997us/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9952\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# keras모델 불러오기\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# seed값 설정\n",
    "numpy.random.seed(10)\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y_encoded, test_size=0.3, random_state=120)\n",
    "\n",
    "# 모델 설정\n",
    "# Dense값 조절( input_dim)\n",
    "# 순서대로 입력층, hidden layer층, output층\n",
    "# input_dim뜻:입력 데이터에서 몇 개의 값을 가져올 것인지\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "history = model.fit(X,y_encoded, epochs=200, batch_size=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029DE3A37A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 출력\n",
    "pred = model.predict(X_test)\n",
    "pred_arr = []\n",
    "for i in pred:\n",
    "    if i[0] >= 0.5:\n",
    "       pred_arr.append(1)\n",
    "    else:\n",
    "        pred_arr.append(0)\n",
    "pred_arr\n",
    "\n",
    "result = accuracy_score(pred_arr, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "print(\"\\n Accuracy: %.4f\" %(model.evaluate(X,y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.hidden layer층(네트워크 수 줄이기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.5048\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6873 - accuracy: 0.5337\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.6154\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6394\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6538\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.7067\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.7019\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7163\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7740\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7692\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7548\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7788\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7837\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7788\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7933\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7933\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7981\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.8125\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8077\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8125\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.8173\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7885\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8077\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8173\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8077\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8173\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8221\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7981\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8269\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8125\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8077\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8221\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.8317\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8221\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8029\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3997 - accuracy: 0.8125\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8269\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8125\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8558\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8413\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8317\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.8317\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8317\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8413\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8462\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8413\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8317\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8221\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8317\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8510\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8510\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8702\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8558\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8702\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8606\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8413\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 974us/step - loss: 0.3501 - accuracy: 0.8702\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8558\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8606\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8462\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 975us/step - loss: 0.3474 - accuracy: 0.8558\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8750\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8750\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8606\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8413\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8654\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8750\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8606\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8750\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8798\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.8750\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8798\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3183 - accuracy: 0.8798\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8750\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8798\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8750\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8846\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8606\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8894\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.8798\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 949us/step - loss: 0.3076 - accuracy: 0.8942\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.8942\n",
      "Epoch 83/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8846\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8846\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8846\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8990\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8798\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8846\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8942\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.9038\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2879 - accuracy: 0.8942\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.8990\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.8894\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2816 - accuracy: 0.8990\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8942\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.8750\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2843 - accuracy: 0.8846\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2765 - accuracy: 0.9087\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2717 - accuracy: 0.8990\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.8942\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.9038\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8990\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9038\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9038\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.9087\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2650 - accuracy: 0.9038\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8942\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.9135\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.9038\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.9087\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.9183\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2538 - accuracy: 0.9038\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8990\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9135\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9375\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2547 - accuracy: 0.9087\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9038\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9327\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9087\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9183\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9375\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9183\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9135\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9279\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9327\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9327\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9231\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9279\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9279\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2281 - accuracy: 0.9135\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9038\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9231\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9471\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9087\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9327\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9231\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9279\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9423\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9327\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9471\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.9423\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9183\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9423\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9375\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9279\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.9375\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9423\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9471\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9471\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9423\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9519\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9375\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9423\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9423\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9327\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9279\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9663\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9519\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9471\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9375\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9519\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9471\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9567\n",
      "Epoch 164/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9519\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9519\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9567\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9519\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9615\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9615\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9519\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9567\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9519\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9519\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9471\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9663\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9663\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9615\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9567\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9615\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9519\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9615\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 986us/step - loss: 0.1682 - accuracy: 0.9567\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9712\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9663\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9615\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9615\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.9663\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9567\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.9663\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9663\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.9615\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9615\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9423\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9760\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9760\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9519\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9760\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9663\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1483 - accuracy: 0.9615\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9760\n",
      "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029DE73DD940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9682539682539683"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y_encoded, test_size=0.3, random_state=120)\n",
    "\n",
    "\n",
    "# 모델 설정\n",
    "# Dense값 조절(input_dim)\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "# hidden layer층\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "history = model.fit(X,y_encoded, epochs=200, batch_size=5)\n",
    "\n",
    "# 결과 출력\n",
    "pred = model.predict(X_test)\n",
    "pred_arr = []\n",
    "for i in pred:\n",
    "    if i[0] >= 0.5:\n",
    "       pred_arr.append(1)\n",
    "    else:\n",
    "        pred_arr.append(0)\n",
    "pred_arr\n",
    "\n",
    "result = accuracy_score(pred_arr, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.epochs값 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 정확도가 100으로 나오는 건 말도 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "42/42 [==============================] - 1s 2ms/step - loss: 0.6855 - accuracy: 0.5481\n",
      "Epoch 2/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.5962\n",
      "Epoch 3/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6875\n",
      "Epoch 4/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.6635\n",
      "Epoch 5/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6779\n",
      "Epoch 6/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7019\n",
      "Epoch 7/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7404\n",
      "Epoch 8/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7596\n",
      "Epoch 9/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7933\n",
      "Epoch 10/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7837\n",
      "Epoch 11/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8173\n",
      "Epoch 12/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8077\n",
      "Epoch 13/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7885\n",
      "Epoch 14/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8077\n",
      "Epoch 15/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8221\n",
      "Epoch 16/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8125\n",
      "Epoch 17/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8125\n",
      "Epoch 18/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8269\n",
      "Epoch 19/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8221\n",
      "Epoch 20/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8221\n",
      "Epoch 21/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8125\n",
      "Epoch 22/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8317\n",
      "Epoch 23/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8413\n",
      "Epoch 24/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8173\n",
      "Epoch 25/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8413\n",
      "Epoch 26/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8654\n",
      "Epoch 27/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8606\n",
      "Epoch 28/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8317\n",
      "Epoch 29/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8558\n",
      "Epoch 30/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8654\n",
      "Epoch 31/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8606\n",
      "Epoch 32/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8702\n",
      "Epoch 33/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8942\n",
      "Epoch 34/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8798\n",
      "Epoch 35/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8558\n",
      "Epoch 36/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8702\n",
      "Epoch 37/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8990\n",
      "Epoch 38/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.9038\n",
      "Epoch 39/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2717 - accuracy: 0.8846\n",
      "Epoch 40/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2605 - accuracy: 0.9038\n",
      "Epoch 41/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.8894\n",
      "Epoch 42/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.9087\n",
      "Epoch 43/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9231\n",
      "Epoch 44/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.9038\n",
      "Epoch 45/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.9183\n",
      "Epoch 46/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9279\n",
      "Epoch 47/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.9087\n",
      "Epoch 48/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.9135\n",
      "Epoch 49/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9038\n",
      "Epoch 50/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.9231\n",
      "Epoch 51/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.9375\n",
      "Epoch 52/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9135\n",
      "Epoch 53/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9183\n",
      "Epoch 54/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9183\n",
      "Epoch 55/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9423\n",
      "Epoch 56/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.9327\n",
      "Epoch 57/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9279\n",
      "Epoch 58/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9279\n",
      "Epoch 59/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9375\n",
      "Epoch 60/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.9135\n",
      "Epoch 61/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9279\n",
      "Epoch 62/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9279\n",
      "Epoch 63/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9375\n",
      "Epoch 64/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.9375\n",
      "Epoch 65/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9279\n",
      "Epoch 66/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9567\n",
      "Epoch 67/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9423\n",
      "Epoch 68/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9375\n",
      "Epoch 69/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9327\n",
      "Epoch 70/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9615\n",
      "Epoch 71/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9471\n",
      "Epoch 72/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9567\n",
      "Epoch 73/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1433 - accuracy: 0.9471\n",
      "Epoch 74/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9567\n",
      "Epoch 75/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9423\n",
      "Epoch 76/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1249 - accuracy: 0.9760\n",
      "Epoch 77/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9567\n",
      "Epoch 78/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9663\n",
      "Epoch 79/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9519\n",
      "Epoch 80/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9567\n",
      "Epoch 81/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9663\n",
      "Epoch 82/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9760\n",
      "Epoch 83/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9712\n",
      "Epoch 84/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9712\n",
      "Epoch 85/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9712\n",
      "Epoch 86/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9471\n",
      "Epoch 87/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9712\n",
      "Epoch 88/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9663\n",
      "Epoch 89/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0980 - accuracy: 0.9712\n",
      "Epoch 90/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.9808\n",
      "Epoch 91/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9663\n",
      "Epoch 92/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9808\n",
      "Epoch 93/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9760\n",
      "Epoch 94/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9856\n",
      "Epoch 95/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9856\n",
      "Epoch 96/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9904\n",
      "Epoch 97/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9808\n",
      "Epoch 98/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9808\n",
      "Epoch 99/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.9856\n",
      "Epoch 100/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9904\n",
      "Epoch 101/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9904\n",
      "Epoch 102/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9856\n",
      "Epoch 103/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9856\n",
      "Epoch 104/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9904\n",
      "Epoch 105/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9904\n",
      "Epoch 106/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9904\n",
      "Epoch 107/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9904\n",
      "Epoch 108/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9856\n",
      "Epoch 109/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9856\n",
      "Epoch 110/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9856\n",
      "Epoch 111/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9952\n",
      "Epoch 112/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0531 - accuracy: 0.9904\n",
      "Epoch 113/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0482 - accuracy: 0.9952\n",
      "Epoch 114/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9904\n",
      "Epoch 115/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9904\n",
      "Epoch 116/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9952\n",
      "Epoch 117/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9904\n",
      "Epoch 118/120\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9952\n",
      "Epoch 119/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9952\n",
      "Epoch 120/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9904\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9841269841269841"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X,y_encoded, test_size=0.3, random_state=120)\n",
    "# 모델 설정\n",
    "# Dense값 조절( input_dim)\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "history = model.fit(X,y_encoded, epochs=120, batch_size=5)\n",
    "\n",
    "# 결과 출력\n",
    "pred = model.predict(X_test)\n",
    "pred_arr = []\n",
    "for i in pred:\n",
    "    if i[0] >= 0.5:\n",
    "       pred_arr.append(1)\n",
    "    else:\n",
    "        pred_arr.append(0)\n",
    "pred_arr\n",
    "\n",
    "result = accuracy_score(pred_arr, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.X_train,y_train으로 분리하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "42/42 [==============================] - 1s 1ms/step - loss: 0.6740 - accuracy: 0.6442\n",
      "Epoch 2/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6635\n",
      "Epoch 3/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.7548\n",
      "Epoch 4/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.7500\n",
      "Epoch 5/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7356\n",
      "Epoch 6/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7740\n",
      "Epoch 7/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7981\n",
      "Epoch 8/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7692\n",
      "Epoch 9/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8125\n",
      "Epoch 10/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8029\n",
      "Epoch 11/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8077\n",
      "Epoch 12/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7981\n",
      "Epoch 13/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.8077\n",
      "Epoch 14/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8077\n",
      "Epoch 15/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8317\n",
      "Epoch 16/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8077\n",
      "Epoch 17/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.7933\n",
      "Epoch 18/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8413\n",
      "Epoch 19/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8365\n",
      "Epoch 20/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8269\n",
      "Epoch 21/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8413\n",
      "Epoch 22/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8317\n",
      "Epoch 23/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8654\n",
      "Epoch 24/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8462\n",
      "Epoch 25/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8702\n",
      "Epoch 26/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8510\n",
      "Epoch 27/120\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8654\n",
      "Epoch 28/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8365\n",
      "Epoch 29/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8750\n",
      "Epoch 30/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8798\n",
      "Epoch 31/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8846\n",
      "Epoch 32/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3053 - accuracy: 0.8846\n",
      "Epoch 33/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.3044 - accuracy: 0.8846\n",
      "Epoch 34/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8990\n",
      "Epoch 35/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8798\n",
      "Epoch 36/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2924 - accuracy: 0.8846\n",
      "Epoch 37/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8942\n",
      "Epoch 38/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2828 - accuracy: 0.9087\n",
      "Epoch 39/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.9038\n",
      "Epoch 40/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8894\n",
      "Epoch 41/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2681 - accuracy: 0.8990\n",
      "Epoch 42/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.9087\n",
      "Epoch 43/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.9231\n",
      "Epoch 44/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8942\n",
      "Epoch 45/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.8942\n",
      "Epoch 46/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.9279\n",
      "Epoch 47/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.9087\n",
      "Epoch 48/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.8894\n",
      "Epoch 49/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9279\n",
      "Epoch 50/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.9183\n",
      "Epoch 51/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9375\n",
      "Epoch 52/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9135\n",
      "Epoch 53/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9327\n",
      "Epoch 54/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9279\n",
      "Epoch 55/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.9375\n",
      "Epoch 56/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.9423\n",
      "Epoch 57/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9375\n",
      "Epoch 58/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9375\n",
      "Epoch 59/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9279\n",
      "Epoch 60/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.9327\n",
      "Epoch 61/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9471\n",
      "Epoch 62/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9375\n",
      "Epoch 63/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.9519\n",
      "Epoch 64/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9375\n",
      "Epoch 65/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9567\n",
      "Epoch 66/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9519\n",
      "Epoch 67/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1573 - accuracy: 0.9615\n",
      "Epoch 68/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9567\n",
      "Epoch 69/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9327\n",
      "Epoch 70/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9567\n",
      "Epoch 71/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9663\n",
      "Epoch 72/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9519\n",
      "Epoch 73/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9519\n",
      "Epoch 74/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.9808\n",
      "Epoch 75/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9760\n",
      "Epoch 76/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9663\n",
      "Epoch 77/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9856\n",
      "Epoch 78/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.9712\n",
      "Epoch 79/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9663\n",
      "Epoch 80/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9808\n",
      "Epoch 81/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9808\n",
      "Epoch 82/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9856\n",
      "Epoch 83/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9760\n",
      "Epoch 84/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9760\n",
      "Epoch 85/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9808\n",
      "Epoch 86/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9567\n",
      "Epoch 87/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9856\n",
      "Epoch 88/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1007 - accuracy: 0.9760\n",
      "Epoch 89/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9856\n",
      "Epoch 90/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9856\n",
      "Epoch 91/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9760\n",
      "Epoch 92/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.9856\n",
      "Epoch 93/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9856\n",
      "Epoch 94/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9856\n",
      "Epoch 95/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9856\n",
      "Epoch 96/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0800 - accuracy: 0.9760\n",
      "Epoch 97/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9856\n",
      "Epoch 98/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9856\n",
      "Epoch 99/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9856\n",
      "Epoch 100/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9856\n",
      "Epoch 101/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9904\n",
      "Epoch 102/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9856\n",
      "Epoch 103/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9856\n",
      "Epoch 104/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9856\n",
      "Epoch 105/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9856\n",
      "Epoch 106/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9904\n",
      "Epoch 107/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9856\n",
      "Epoch 108/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9856\n",
      "Epoch 109/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9904\n",
      "Epoch 110/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9856\n",
      "Epoch 111/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9904\n",
      "Epoch 112/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9904\n",
      "Epoch 113/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9952\n",
      "Epoch 114/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9904\n",
      "Epoch 115/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9952\n",
      "Epoch 116/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9904\n",
      "Epoch 117/120\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9952\n",
      "Epoch 118/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9952\n",
      "Epoch 119/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 120/120\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9952\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 1.0000\n",
      "[0.031994644552469254, 1.0]\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y_encoded, test_size=0.3, random_state=120)\n",
    "\n",
    "# 모델 설정\n",
    "# Dense값 조절( input_dim)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(12, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "history = model.fit(X,y_encoded, epochs=120, batch_size=5)\n",
    "\n",
    "print(model.evaluate(X,y_encoded))\n",
    "\n",
    "# 결과 출력\n",
    "pred = model.predict(X_test)\n",
    "pred_arr = []\n",
    "for i in pred:\n",
    "    if i[0] >= 0.5:\n",
    "       pred_arr.append(1)\n",
    "    else:\n",
    "        pred_arr.append(0)\n",
    "pred_arr\n",
    "\n",
    "result = accuracy_score(pred_arr, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://i-am-eden.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9984443e-01],\n",
       "       [9.0986228e-01],\n",
       "       [3.0320170e-04],\n",
       "       [3.3711756e-03],\n",
       "       [9.9805802e-01],\n",
       "       [1.5631404e-03],\n",
       "       [9.9998230e-01],\n",
       "       [9.6846491e-01],\n",
       "       [9.2492461e-01],\n",
       "       [7.2163033e-01],\n",
       "       [8.5888337e-03],\n",
       "       [9.8958486e-01],\n",
       "       [7.7027953e-03],\n",
       "       [9.9984342e-01],\n",
       "       [9.9938017e-01],\n",
       "       [1.8455917e-02],\n",
       "       [9.9999970e-01],\n",
       "       [6.1154339e-02],\n",
       "       [8.2063320e-04],\n",
       "       [9.0753883e-01],\n",
       "       [4.8957794e-04],\n",
       "       [9.4945985e-01],\n",
       "       [9.9995029e-01],\n",
       "       [5.5232286e-02],\n",
       "       [9.8613542e-01],\n",
       "       [9.9993926e-01],\n",
       "       [7.8398762e-03],\n",
       "       [9.4695425e-01],\n",
       "       [9.8856199e-01],\n",
       "       [9.7679454e-01],\n",
       "       [1.4305294e-02],\n",
       "       [1.2510042e-02],\n",
       "       [9.9941856e-01],\n",
       "       [9.4631666e-01],\n",
       "       [6.9676680e-05],\n",
       "       [1.1365714e-04],\n",
       "       [2.5080342e-02],\n",
       "       [8.2713187e-01],\n",
       "       [7.8569879e-05],\n",
       "       [6.0712053e-05],\n",
       "       [9.8976243e-01],\n",
       "       [9.9987453e-01],\n",
       "       [3.7404401e-03],\n",
       "       [2.5317676e-03],\n",
       "       [6.8212241e-02],\n",
       "       [9.6723062e-01],\n",
       "       [8.1229955e-03],\n",
       "       [1.4790967e-04],\n",
       "       [4.4203978e-02],\n",
       "       [7.0725975e-04],\n",
       "       [8.2365060e-01],\n",
       "       [6.0296112e-01],\n",
       "       [9.4599408e-01],\n",
       "       [9.6276790e-01],\n",
       "       [3.1537921e-04],\n",
       "       [2.0578983e-03],\n",
       "       [9.7288826e-04],\n",
       "       [9.0206915e-01],\n",
       "       [6.4283041e-03],\n",
       "       [9.9994665e-01],\n",
       "       [9.9999738e-01],\n",
       "       [9.6150434e-01],\n",
       "       [1.4466836e-02]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_test = load_model('model.h5')\n",
    "model_test.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  model학습을 따로 시키고, 기존에 학습시킨 모델을 가지고 최적의 모델예측률을 찾아서, 해당 저장한 모델 버전을 갈아 끼우기만 하면 되는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과적합에 대해서 예측률을 높이려면 여러가지 epoch값,layer들을 조절 시키는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### history.history 하면 정확값과 예측값이 출력됨. 그럼 그래프가 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
